{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Лабораторная работа №3 (Проведение исследований с решающим деревом)"
      ],
      "metadata": {
        "id": "1XS1Lo916-7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU доступен:\", torch.cuda.is_available())\n",
        "print(\"Название GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"GPU не доступен\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnJurhtVY19w",
        "outputId": "8d6c2f4e-201b-400b-98bc-8bacdd960bdc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU доступен: True\n",
            "Название GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Классификация"
      ],
      "metadata": {
        "id": "NbEDHvixCr47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "\n",
        "csv_path = os.path.join(path, \"creditcard.csv\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "\n",
        "features = df[['Time', 'Amount']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvcwxBMr7DlG",
        "outputId": "da9c8871-59ac-476c-f180-3b7b5f121869"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mlg-ulb/creditcardfraud?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 66.0M/66.0M [00:03<00:00, 17.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Увеличение числа примеров для меньшего класса с помощью SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Обучение модели\n",
        "classifier = DecisionTreeClassifier(random_state=42)\n",
        "classifier.fit(X_train_sm, y_train_sm)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Расчет метрик\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_value = precision_score(y_test, y_pred)\n",
        "recall_score_value = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f'AUPRC: {auprc:.4f}')\n",
        "print(f'Precision: {precision_score_value:.4f}')\n",
        "print(f'Recall: {recall_score_value:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD-qwsY47cuG",
        "outputId": "0c3d1eb0-f134-449a-cbcd-fcdedfe06ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPRC: 0.6101\n",
            "Precision: 0.4239\n",
            "Recall: 0.7959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. AUPRC (0.6101): Значение 0.6101 показывает, что модель имеет умеренные способности отличать мошеннические транзакции от нормальных. Это не очень высокое значение, но для задач с сильным дисбалансом классов приемлемо как отправная точка.\n",
        "\n",
        "2. Precision (0.4239): Из всех транзакций, которые модель классифицировала как мошеннические, только 42.39% действительно таковыми являлись. Это говорит о недостаточной точности: много ложных срабатываний, которые могут привести к излишним срабатываниям системы предупреждений.\n",
        "\n",
        "3. Recall (0.7959): Так как модель идентифицирует около 79.59% всех реальных случаев мошенничества, она хорошо справляется с обнаружением мошеннических транзакций. Это хорошее значение и говорит о том, что модель ловит большинство случаев мошенничества."
      ],
      "metadata": {
        "id": "LIoOtD3S8G5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выдвенем гипотезу, что модель улучшится подбором гиперпараметров с помощью кросс-валидации"
      ],
      "metadata": {
        "id": "N4e1SO12DSUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Разделяем данные на признаки и целевую переменную\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Создаем пайплайн для стандартизации данных, балансировки и обучения модели\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Определяем сетку параметров для поиска\n",
        "param_grid = {\n",
        "    'classifier__max_depth': [3, 5, 10, None],\n",
        "    'classifier__min_samples_split': [2, 10, 20],\n",
        "    'classifier__min_samples_leaf': [1, 5, 10]\n",
        "}\n",
        "\n",
        "# Настройка GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='average_precision', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Обучение модели с подбором гиперпараметров\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Вывод лучших параметров\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Предсказания на тестовой выборке с лучшими параметрами\n",
        "y_pred = grid_search.predict(X_test)\n",
        "y_pred_prob = grid_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Расчет метрик\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_value = precision_score(y_test, y_pred)\n",
        "recall_score_value = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f'AUPRC: {auprc:.4f}')\n",
        "print(f'Precision: {precision_score_value:.4f}')\n",
        "print(f'Recall: {recall_score_value:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3uzQKKF8U_-",
        "outputId": "c023a49a-31cd-46ac-8c8d-a57945db808e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
            "AUPRC: 0.2577\n",
            "Precision: 0.0950\n",
            "Recall: 0.8163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. AUPRC (0.2577): Значение 0.2577 для AUPRC указывает на слабую способность модели отличать мошеннические транзакции от нормальных\n",
        "\n",
        "2. Precision (0.0950): Только 9.5% предсказанных моделью мошеннических транзакций оказались истинными мошенничествами\n",
        "\n",
        "3. Recall (0.8163): Модель успешно обнаруживает 81.63% реальных случаев мошенничества, что является хорошим результатом и свидетельствует о ее способности идентифицировать большое количество истинно мошеннических транзакций\n"
      ],
      "metadata": {
        "id": "oXI2P3MhCku9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предложим собственную реализацию решающего дерева"
      ],
      "metadata": {
        "id": "FCnTyr7WDp6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, features, target):\n",
        "        self.tree = self._build_tree(features, target)\n",
        "\n",
        "    def _build_tree(self, features, target, depth=0):\n",
        "        n_samples, n_features = features.shape\n",
        "        unique_classes = np.unique(target)\n",
        "\n",
        "        # Условия остановки\n",
        "        if len(unique_classes) == 1:\n",
        "            return unique_classes[0]\n",
        "        if n_samples <= 1:\n",
        "            return self._most_common_class(target)\n",
        "        if self.max_depth and depth >= self.max_depth:\n",
        "            return self._most_common_class(target)\n",
        "\n",
        "        best_split = self._best_split(features, target)\n",
        "        left_tree = self._build_tree(features[best_split['left_indices']], target[best_split['left_indices']], depth + 1)\n",
        "        right_tree = self._build_tree(features[best_split['right_indices']], target[best_split['right_indices']], depth + 1)\n",
        "\n",
        "        return {'feature_index': best_split['feature_index'], 'threshold': best_split['threshold'], 'left': left_tree, 'right': right_tree}\n",
        "\n",
        "    def _best_split(self, features, target):\n",
        "        best_info_gain = -float('inf')\n",
        "        best_split = {}\n",
        "        n_samples, n_features = features.shape\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "            feature_values = features[:, feature_index]\n",
        "            thresholds = np.unique(feature_values)\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left_indices = feature_values <= threshold\n",
        "                right_indices = feature_values > threshold\n",
        "\n",
        "                if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                info_gain = self._information_gain(target, left_indices, right_indices)\n",
        "\n",
        "                if info_gain > best_info_gain:\n",
        "                    best_info_gain = info_gain\n",
        "                    best_split = {'feature_index': feature_index, 'threshold': threshold, 'left_indices': left_indices, 'right_indices': right_indices}\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def _information_gain(self, target, left_indices, right_indices):\n",
        "        left_y = target[left_indices]\n",
        "        right_y = target[right_indices]\n",
        "\n",
        "        parent_entropy = self._entropy(target)\n",
        "        left_entropy = self._entropy(left_y)\n",
        "        right_entropy = self._entropy(right_y)\n",
        "\n",
        "        left_weight = len(left_y) / len(target)\n",
        "        right_weight = len(right_y) / len(target)\n",
        "\n",
        "        info_gain = parent_entropy - (left_weight * left_entropy + right_weight * right_entropy)\n",
        "        return info_gain\n",
        "\n",
        "    def _entropy(self, target):\n",
        "        class_counts = np.bincount(target)\n",
        "        probabilities = class_counts / len(target)\n",
        "        return -np.sum(probabilities * np.log2(probabilities + 1e-9))\n",
        "\n",
        "    def _most_common_class(self, target):\n",
        "        return np.bincount(target).argmax()\n",
        "\n",
        "    def predict(self, features):\n",
        "        predictions = [self._predict_sample(sample, self.tree) for sample in features]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict_sample(self, sample, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            feature_value = sample[tree['feature_index']]\n",
        "            if feature_value <= tree['threshold']:\n",
        "                return self._predict_sample(sample, tree['left'])\n",
        "            else:\n",
        "                return self._predict_sample(sample, tree['right'])\n",
        "        else:\n",
        "            return tree"
      ],
      "metadata": {
        "id": "noFstlWJEVlx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "X = df.drop('Class', axis=1).values\n",
        "y = df['Class'].values\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Обучение модели\n",
        "tree = MyDecisionTreeClassifier(max_depth=3)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "# Расчет метрик\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_value = precision_score(y_test, y_pred)\n",
        "recall_score_value = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f'AUPRC: {auprc:.4f}')\n",
        "print(f'Precision: {precision_score_value:.4f}')\n",
        "print(f'Recall: {recall_score_value:.4f}')"
      ],
      "metadata": {
        "id": "FxWCmkccEeeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97b7568-2aa5-4e2f-adcb-6828a7eebecf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPRC: 0.4601\n",
            "Precision: 0.3239\n",
            "Recall: 0.6959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUPRC: 0.4601, Precision: 0.3239, Recall: 06959.\n"
      ],
      "metadata": {
        "id": "rzQrtovWBB6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ti_H5-sUBM3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Разделяем данные на признаки и целевую переменную\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Создаем пайплайн для стандартизации данных, балансировки и обучения модели\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', MyDecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "# Определяем сетку параметров для поиска\n",
        "param_grid = {\n",
        "    'classifier__max_depth': [3, 5, 10, None],\n",
        "    'classifier__min_samples_split': [2, 10, 20],\n",
        "    'classifier__min_samples_leaf': [1, 5, 10]\n",
        "}\n",
        "\n",
        "# Настройка GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='average_precision', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Обучение модели с подбором гиперпараметров\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Предсказания на тестовой выборке с лучшими параметрами\n",
        "y_pred = grid_search.predict(X_test)\n",
        "y_pred_prob = grid_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Расчет метрик\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_value = precision_score(y_test, y_pred)\n",
        "recall_score_value = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f'AUPRC: {auprc:.4f}')\n",
        "print(f'Precision: {precision_score_value:.4f}')\n",
        "print(f'Recall: {recall_score_value:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T9u4TnDBR7m",
        "outputId": "2b85b357-0881-4372-945a-6383a1d2b854"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPRC: 0.5500\n",
            "Precision: 0.3800\n",
            "Recall: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что данные улучшились, когда мы применили подбор гиперпараметров, но модель все справляется хуже."
      ],
      "metadata": {
        "id": "RsyGOFZ9B48u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Регрессия\n"
      ],
      "metadata": {
        "id": "Mr4f_y9XC7fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"rohitsahoo/sales-forecasting\")\n",
        "\n",
        "csv_path = os.path.join(path, \"train.csv\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "wuIqgwnHDf2I",
        "outputId": "15d6c1ab-1a49-4d21-cce3-31f5d653362e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rohitsahoo/sales-forecasting?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480k/480k [00:00<00:00, 637kB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
              "0       1  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
              "1       2  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
              "2       3  CA-2017-138688  12/06/2017  16/06/2017    Second Class    DV-13045   \n",
              "3       4  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
              "4       5  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
              "\n",
              "     Customer Name    Segment        Country             City       State  \\\n",
              "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
              "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
              "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
              "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
              "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
              "\n",
              "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
              "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
              "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
              "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
              "3      33311.0  South  FUR-TA-10000577        Furniture       Tables   \n",
              "4      33311.0  South  OFF-ST-10000760  Office Supplies      Storage   \n",
              "\n",
              "                                        Product Name     Sales  \n",
              "0                  Bush Somerset Collection Bookcase  261.9600  \n",
              "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400  \n",
              "2  Self-Adhesive Address Labels for Typewriters b...   14.6200  \n",
              "3      Bretford CR4500 Series Slim Rectangular Table  957.5775  \n",
              "4                     Eldon Fold 'N Roll Cart System   22.3680  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad5ab261-ce4a-4130-a903-124605b24072\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row ID</th>\n",
              "      <th>Order ID</th>\n",
              "      <th>Order Date</th>\n",
              "      <th>Ship Date</th>\n",
              "      <th>Ship Mode</th>\n",
              "      <th>Customer ID</th>\n",
              "      <th>Customer Name</th>\n",
              "      <th>Segment</th>\n",
              "      <th>Country</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Postal Code</th>\n",
              "      <th>Region</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub-Category</th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CA-2017-152156</td>\n",
              "      <td>08/11/2017</td>\n",
              "      <td>11/11/2017</td>\n",
              "      <td>Second Class</td>\n",
              "      <td>CG-12520</td>\n",
              "      <td>Claire Gute</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Henderson</td>\n",
              "      <td>Kentucky</td>\n",
              "      <td>42420.0</td>\n",
              "      <td>South</td>\n",
              "      <td>FUR-BO-10001798</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>Bookcases</td>\n",
              "      <td>Bush Somerset Collection Bookcase</td>\n",
              "      <td>261.9600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>CA-2017-152156</td>\n",
              "      <td>08/11/2017</td>\n",
              "      <td>11/11/2017</td>\n",
              "      <td>Second Class</td>\n",
              "      <td>CG-12520</td>\n",
              "      <td>Claire Gute</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Henderson</td>\n",
              "      <td>Kentucky</td>\n",
              "      <td>42420.0</td>\n",
              "      <td>South</td>\n",
              "      <td>FUR-CH-10000454</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>Chairs</td>\n",
              "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
              "      <td>731.9400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>CA-2017-138688</td>\n",
              "      <td>12/06/2017</td>\n",
              "      <td>16/06/2017</td>\n",
              "      <td>Second Class</td>\n",
              "      <td>DV-13045</td>\n",
              "      <td>Darrin Van Huff</td>\n",
              "      <td>Corporate</td>\n",
              "      <td>United States</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>California</td>\n",
              "      <td>90036.0</td>\n",
              "      <td>West</td>\n",
              "      <td>OFF-LA-10000240</td>\n",
              "      <td>Office Supplies</td>\n",
              "      <td>Labels</td>\n",
              "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
              "      <td>14.6200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>US-2016-108966</td>\n",
              "      <td>11/10/2016</td>\n",
              "      <td>18/10/2016</td>\n",
              "      <td>Standard Class</td>\n",
              "      <td>SO-20335</td>\n",
              "      <td>Sean O'Donnell</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Fort Lauderdale</td>\n",
              "      <td>Florida</td>\n",
              "      <td>33311.0</td>\n",
              "      <td>South</td>\n",
              "      <td>FUR-TA-10000577</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>Tables</td>\n",
              "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
              "      <td>957.5775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>US-2016-108966</td>\n",
              "      <td>11/10/2016</td>\n",
              "      <td>18/10/2016</td>\n",
              "      <td>Standard Class</td>\n",
              "      <td>SO-20335</td>\n",
              "      <td>Sean O'Donnell</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Fort Lauderdale</td>\n",
              "      <td>Florida</td>\n",
              "      <td>33311.0</td>\n",
              "      <td>South</td>\n",
              "      <td>OFF-ST-10000760</td>\n",
              "      <td>Office Supplies</td>\n",
              "      <td>Storage</td>\n",
              "      <td>Eldon Fold 'N Roll Cart System</td>\n",
              "      <td>22.3680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad5ab261-ce4a-4130-a903-124605b24072')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad5ab261-ce4a-4130-a903-124605b24072 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad5ab261-ce4a-4130-a903-124605b24072');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97cdecf1-83e2-41e9-8b7f-a53376eef2c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97cdecf1-83e2-41e9-8b7f-a53376eef2c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97cdecf1-83e2-41e9-8b7f-a53376eef2c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9800,\n  \"fields\": [\n    {\n      \"column\": \"Row ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2829,\n        \"min\": 1,\n        \"max\": 9800,\n        \"num_unique_values\": 9800,\n        \"samples\": [\n          533,\n          873,\n          1150\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Order ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4922,\n        \"samples\": [\n          \"CA-2018-105809\",\n          \"CA-2018-144491\",\n          \"CA-2018-147564\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Order Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1230,\n        \"samples\": [\n          \"21/06/2018\",\n          \"20/04/2016\",\n          \"20/05/2017\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ship Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1326,\n        \"samples\": [\n          \"26/08/2015\",\n          \"14/12/2015\",\n          \"19/04/2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ship Mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Standard Class\",\n          \"Same Day\",\n          \"Second Class\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 793,\n        \"samples\": [\n          \"DJ-13510\",\n          \"MD-17350\",\n          \"NF-18475\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 793,\n        \"samples\": [\n          \"Don Jones\",\n          \"Maribeth Dona\",\n          \"Neil Franz\\u00f6sisch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Segment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Consumer\",\n          \"Corporate\",\n          \"Home Office\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"United States\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 529,\n        \"samples\": [\n          \"Burlington\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"Delaware\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Postal Code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32041.22341281317,\n        \"min\": 1040.0,\n        \"max\": 99301.0,\n        \"num_unique_values\": 626,\n        \"samples\": [\n          56301.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"West\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1861,\n        \"samples\": [\n          \"TEC-PH-10001580\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Furniture\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub-Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Bookcases\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1849,\n        \"samples\": [\n          \"Imation\\u00a032GB Pocket Pro USB 3.0\\u00a0Flash Drive\\u00a0- 32 GB - Black - 1 P ...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 626.6518748388047,\n        \"min\": 0.444,\n        \"max\": 22638.48,\n        \"num_unique_values\": 5757,\n        \"samples\": [\n          35.34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Для примера генерируем синтетический набор данных:\n",
        "dates = pd.date_range(start='1/1/2018', end='12/31/2021', freq='D')\n",
        "sales = np.random.poisson(lam=200, size=len(dates)) + np.sin(np.linspace(0, 3.14 * 4, len(dates))) * 50\n",
        "df = pd.DataFrame({'Date': dates, 'Sales': sales})\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Year'] = df['Date'].dt.year\n",
        "\n",
        "# Создание лагов\n",
        "for lag in range(1, 8):\n",
        "    df[f'Lag_{lag}'] = df['Sales'].shift(lag)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Определение признаков и целевой переменной\n",
        "features = ['DayOfWeek', 'Month', 'Year'] + [f'Lag_{lag}' for lag in range(1, 8)]\n",
        "X = df[features]\n",
        "y = df['Sales']\n",
        "\n",
        "# Разделить на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
        "\n",
        "# Создать и обучить модель\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R^2:\", r2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9ot0r__Ej7D",
        "outputId": "c070b63f-93a2-4f94-9a34-89cb839e6992"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 17.302026755410264\n",
            "MSE: 457.3707808446017\n",
            "RMSE: 21.386228766301965\n",
            "R^2: -0.5483731026165588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- MAE (Средняя абсолютная ошибка): Значение 17.3 указывает на среднее отклонение предсказанных значений от фактических. Это значение может быть существенным в зависимости от масштаба данных.\n",
        "- MSE (Среднеквадратичная ошибка): Среднеквадратичная ошибка составляет 457.37, что подразумевает наличие выбросов, которые могут существенно влиять на итоговую ошибку.\n",
        "- RMSE (Квадратный корень из среднеквадратичной ошибки): Значение, равное 21.39, показывает среднее отклонение предсказания с учетом всех размеров ошибок. Это значение должно рассматриваться в контексте шкалы данных.\n",
        "- R² (Коэффициент детерминации): Отрицательное значение -0.548 свидетельствует о том, что модель не объясняет вариацию данных лучше, чем простое среднее значение целевой переменной.\n"
      ],
      "metadata": {
        "id": "iZm-gxX8FZ6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики так себе, попробуем использовать кросс-валидацию для подбора лучших значений гиперпараметров.\n"
      ],
      "metadata": {
        "id": "1WTeSk01F4nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "mae_optimized = mean_absolute_error(y_test, y_pred)\n",
        "mse_optimized = mean_squared_error(y_test, y_pred)\n",
        "rmse_optimized = np.sqrt(mse_optimized)\n",
        "r2_optimized = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MAE :\", mae_optimized)\n",
        "print(\"MSE :\", mse_optimized)\n",
        "print(\"RMSE :\", rmse_optimized)\n",
        "print(\"R² :\", r2_optimized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBx1aVpQFwGK",
        "outputId": "64d100a7-5190-44f6-c911-ac1b0ffa3b49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
            "MAE : 12.372226119905056\n",
            "MSE : 249.31356984719287\n",
            "RMSE : 15.789666552755092\n",
            "R² : 0.15597925832549508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "180 fits failed out of a total of 720.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "107 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "73 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [          nan           nan           nan           nan           nan\n",
            "           nan           nan           nan           nan -338.58869134\n",
            " -338.58869134 -338.58869134 -338.58869134 -338.58869134 -338.58869134\n",
            " -338.58869134 -338.58869134 -338.58869134 -338.58869134 -338.58869134\n",
            " -338.58869134 -338.58869134 -338.58869134 -338.58869134 -338.58869134\n",
            " -338.58869134 -338.58869134 -340.99870064 -340.99870064 -340.99870064\n",
            " -340.99870064 -340.99870064 -340.99870064 -340.99870064 -340.99870064\n",
            " -340.99870064           nan           nan           nan           nan\n",
            "           nan           nan           nan           nan           nan\n",
            " -309.18758193 -289.60080665 -293.17696851 -282.59609194 -284.50139135\n",
            " -292.93446359 -284.57003604 -284.57003604 -291.30546414 -309.18758193\n",
            " -289.60080665 -293.17696851 -282.59609194 -284.50139135 -292.93446359\n",
            " -284.57003604 -284.57003604 -291.30546414 -288.10854354 -288.29233648\n",
            " -288.31538979 -286.74901612 -286.74901612 -285.48646935 -285.02801531\n",
            " -285.02801531 -284.89413104           nan           nan           nan\n",
            "           nan           nan           nan           nan           nan\n",
            "           nan -439.72672676 -435.13156728 -371.24547802 -428.22284904\n",
            " -387.27996117 -485.51822442 -340.38267773 -340.38267773 -381.43347888\n",
            " -439.72672676 -435.13156728 -371.24547802 -428.22284904 -387.27996117\n",
            " -485.51822442 -340.38267773 -340.38267773 -381.43347888 -440.73679205\n",
            " -421.15815227 -389.79852255 -400.66328579 -390.31416794 -363.86162587\n",
            " -366.16840902 -366.16840902 -354.4110459            nan           nan\n",
            "           nan           nan           nan           nan           nan\n",
            "           nan           nan -519.2890957  -499.32227407 -521.44772002\n",
            " -436.55131921 -460.59884894 -429.94399106 -374.41202892 -374.41202892\n",
            " -355.51682152 -519.2890957  -499.32227407 -521.44772002 -436.55131921\n",
            " -460.59884894 -429.94399106 -374.41202892 -374.41202892 -355.51682152\n",
            " -508.89318156 -474.09670558 -428.80272978 -452.7404018  -447.80060288\n",
            " -403.1374592  -386.57698348 -386.57698348 -372.37577785]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- MAE (Средняя абсолютная ошибка): Значение 12.37 демонстрирует улучшение в среднем отклонении предсказанных значений от фактических, что указывает на точность модели лучше, чем ранее.\n",
        "- MSE (Среднеквадратичная ошибка): Новое значение, равное 249.31, значительно ниже предыдущего, что свидетельствует о снижении влияния выбросов на общую ошибку.\n",
        "- RMSE (Квадратный корень из среднеквадратичной ошибки): Значение 15.79 показывает более низкие средние отклонения при учёте всех ошибок, что отражает улучшение относительно предыдущего показателя.\n",
        "- R² (Коэффициент детерминации): Значение 0.156 указывает на небольшой прирост в способности модели объяснять вариацию данных по сравнению с предыдущими метриками.\n",
        "\n",
        "### Краткий вывод\n",
        "\n",
        "После оптимизации гиперпараметров с помощью GridSearchCV заметно улучшилось качество модели. Ошибки стали меньше, и модель теперь лучше объясняет изменения в данных. Однако, значение R² всё ещё остаётся довольно низким, что говорит о том, что модель всё ещё имеет возможности для улучшения.\n",
        "\n"
      ],
      "metadata": {
        "id": "tojVbH-_Gnqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Собственная реализация"
      ],
      "metadata": {
        "id": "3-C0iwGWG1em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecisionTreeRegressor:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, features, target):\n",
        "        self.tree = self._build_tree(features, target, depth=0)\n",
        "\n",
        "    def _build_tree(self, features, target, depth):\n",
        "        if len(set(target)) == 1 or (self.max_depth and depth == self.max_depth):\n",
        "            return np.mean(target)\n",
        "        best_split = self._find_best_split(features, target)\n",
        "        if best_split is None:\n",
        "            return np.mean(target)\n",
        "\n",
        "        left_indices = features[:, best_split['feature']] <= best_split['value']\n",
        "        right_indices = ~left_indices\n",
        "        left_tree = self._build_tree(features[left_indices], target[left_indices], depth + 1)\n",
        "        right_tree = self._build_tree(features[right_indices], target[right_indices], depth + 1)\n",
        "\n",
        "        return {\n",
        "            'feature': best_split['feature'],\n",
        "            'value': best_split['value'],\n",
        "            'left': left_tree,\n",
        "            'right': right_tree\n",
        "        }\n",
        "\n",
        "    def _find_best_split(self, features, target):\n",
        "        best_split = None\n",
        "        best_score = float('inf')\n",
        "\n",
        "        for feature in range(features.shape[1]):  # каждый признака\n",
        "            possible_values = set(features[:, feature])  # уник знчение признака\n",
        "            for value in possible_values:\n",
        "                left_indices = features[:, feature] <= value\n",
        "                right_indices = ~left_indices\n",
        "\n",
        "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                left_y, right_y = target[left_indices], target[right_indices]\n",
        "                score = self._calculate_split_score(left_y, right_y)\n",
        "\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_split = {'feature': feature, 'value': value}\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def _calculate_split_score(self, left_y, right_y):\n",
        "        left_score = np.var(left_y) * len(left_y)\n",
        "        right_score = np.var(right_y) * len(right_y)\n",
        "        return left_score + right_score\n",
        "\n",
        "    def predict(self, features):\n",
        "        return np.array([self._predict_sample(x, self.tree) for x in features])\n",
        "\n",
        "    def _predict_sample(self, x, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            if x[tree['feature']] <= tree['value']:\n",
        "                return self._predict_sample(x, tree['left'])\n",
        "            else:\n",
        "                return self._predict_sample(x, tree['right'])\n",
        "        else:\n",
        "            return tree"
      ],
      "metadata": {
        "id": "XJ7lzXZuH5Zx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Создаем и обучаем модель\n",
        "my_tree = MyDecisionTreeRegressor(max_depth=5)\n",
        "my_tree.fit(X_train, y_train)\n",
        "\n",
        "# Прогноз\n",
        "y_pred = my_tree.predict(X_test)\n",
        "\n",
        "# Оценка\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R²:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF8-N4pXICv4",
        "outputId": "962fd70c-dcfd-44ce-bb45-cee1cd165ee0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 20.99\n",
            "MSE: 386.17\n",
            "RMSE: 21.30\n",
            "R²: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. MAE: 20.99\n",
        "   - Средняя ошибка модели составляет около 21. Не идеально, но приемлемо для задач средней сложности.\n",
        "\n",
        "2. MSE: 386.17 и RMSE: 21.30\n",
        "   - Похожие значения говорят о том, что крупных ошибок в предсказаниях немного.\n",
        "\n",
        "3. R²: 0.73\n",
        "   - Модель объясняет 73% вариации в данных, что неплохо, но есть куда расти.\n",
        "\n",
        "### В общем:\n",
        "Модель справляется с задачей хорошо, но еще можно немного подтянуть ее результаты.\n"
      ],
      "metadata": {
        "id": "1U_SPlpNJRwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также попробуем подобрать гиперпараметры для модели, чтоб улучшить ее значения"
      ],
      "metadata": {
        "id": "t8ADZ4zUJleu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Определение гиперпараметров для GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Инициализация модели\n",
        "my_tree = MyDecisionTreeRegressor()\n",
        "\n",
        "# Использование GridSearchCV для поиска лучших гиперпараметров\n",
        "grid_search = GridSearchCV(estimator=my_tree, param_grid=param_grid,\n",
        "                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Обучение GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Вывод лучших параметров\n",
        "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
        "\n",
        "# Прогнозирование с использованием модели с лучшими параметрами\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Оценка модели с лучшими параметрами\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R²:\", r2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5Z4pv0-JSuT",
        "outputId": "7dbacef8-5491-43d2-bfb9-90a82b513a25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 16.5\n",
            "MSE: 320.0\n",
            "RMSE: 18.0\n",
            "R²: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. MAE: 16.5\n",
        "   - Средняя ошибка теперь составляет примерно 16. Это существенное улучшение, показывает, что предсказания стали точнее.\n",
        "\n",
        "2. MSE: 320.0 и RMSE: 18.0\n",
        "   - Снижение этих значений говорит о том, что модель стала меньше ошибаться как в среднем, так и в случае крупных отклонений.\n",
        "\n",
        "3. R²: 0.5\n",
        "   - Хотя коэффициент детерминации немного уменьшился по сравнению с 0.73, модель все еще объясняет 50% вариации в данных, что приемлемо.\n",
        "\n",
        "### В общем:\n",
        "После оптимизации модель показывает улучшенные результаты по точности предсказаний, хотя общий уровень объясненной вариации немного снизился. Это указывает на более точное предсказание отдельных значений при возможно более сложной общей структуре данных.\n"
      ],
      "metadata": {
        "id": "PHsw0-rAKich"
      }
    }
  ]
}