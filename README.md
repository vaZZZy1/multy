### Результаты метрик (Проведение исследований с алгоритмом KNN)

#### Классификация

| Модель                      | AUPRC | Average Precision | Precision | Recall |
|-----------------------------|-------|-------------------|-----------|--------|
| scikit-learn до оптимизации | 0.050 | 0.002             | 0.002     | 0.312  |
| scikit-learn после оптимизации | 0.508 | 0.337             | 0.311     | 0.667  |
| Собственная реализация до оптимизации | 0.050 | -                 | 0.00      | 0.00   |
| Собственная реализация после оптимизации | 0.490 | -                 | 0.60      | 0.80   |

#### Регрессия

| Модель                      | MAE     | MSE        | RMSE     | R²       |
|-----------------------------|---------|------------|----------|----------|
| scikit-learn до оптимизации | 226.435 | 573041.413 | 756.995  | 0.142667 |
| scikit-learn после оптимизации | 245.803 | 165005.640 | 406.209  | 0.043023 |
| Собственная реализация до оптимизации | 245.803 | 165005.640 | 406.209  | 0.043023 |
| Собственная реализация после оптимизации | 263.118 | 162683.469 | 403.340  | 0.056491 |

### Краткий вывод

Оптимизация классификационной модели с использованием scikit-learn дала значительные улучшения во всех метриках, повысив способность модели точно определять положительные классы. Собственная реализация также продемонстрировала успешную оптимизацию, несмотря на отсутствие начальных результатов.

Однако оптимизация модели регрессии привела к ухудшению показателей как для scikit-learn, так и для собственной реализации. Это подчеркивает необходимость дальнейшего анализа и настройки гиперпараметров, а также возможного применения дополнительных методов обработки данных или изменения архитектуры модели.

### 
### Классификация (Проведение исследований с логистической и линейной регрессией)

| Модель                 | Этап             | AUPRC   | Precision | Recall  |
|------------------------|------------------|---------|-----------|---------|
| sklearn                | до оптимизации   | 0.7072  | 0.8505    | 0.6149  |
| sklearn                | после оптимизации| 0.7415  | 0.0671    | 0.8784  |
| Собственная реализация | до оптимизации   | 0.5009  | 0.0000    | 0.0000  |
| Собственная реализация | после оптимизации| 0.7415  | 0.0671    | 0.8784  |

### Регрессия

| Модель                 | Этап             | MAE       | MSE            | RMSE      | R²        |
|------------------------|------------------|-----------|----------------|-----------|-----------|
| sklearn                | до оптимизации   | 1620.18   | 4001865.28     | 2000.47   | -0.0971   |
| sklearn                | после оптимизации| 1509.87   | 3674897.07     | 1917.00   | -0.0075   |
| Собственная реализация | до оптимизации   | 1500.38   | 4410675.61     | 2100.16   | -0.2092   |
| Собственная реализация | после оптимизации| 1531.51   | 3674254.87     | 1916.83   | -0.0073   |

### Вывод

Оптимизация улучшила способность моделей различать классы, особенно повышая AUPRC в классификации. В регрессии точность также немного повысилась, но ещё требуется доработка для достижения положительного R².


### Лабораторная работа №3: Проведение исследований с решающим деревом

#### Классификация

| Модель                      | AUPRC | Precision | Recall  |
|-----------------------------|-------|----------|--------|
| scikit-learn до оптимизации | 0.6101 | 0.4239  | 0.7959 |
| scikit-learn после оптимизации | 0.2577 | 0.0950  | 0.8163 |
| Собственная реализация до оптимизации | 0.4601 | 0.3239  | 0.6959 |
| Собственная реализация после оптимизации | 0.5500 | 0.3800  | 0.7300 |

#### Регрессия

| Модель                      | MAE    | MSE       | RMSE    | R²      |
|-----------------------------|--------|-----------|---------|---------|
| scikit-learn до оптимизации | 17.30  | 457.37    | 21.39   | -0.548  |
| scikit-learn после оптимизации | 12.37  | 249.31    | 15.79   | 0.156   |
| Собственная реализация до оптимизации | 20.99  | 386.17    | 21.30   | 0.73    |
| Собственная реализация после оптимизации | 16.50  | 320.00    | 18.00   | 0.50    |

### Результаты лабораторной работы 4 (Проведение исследований со случайным лесом)

#### Классификация

| Модель                      | AUPRC |  Precision | Recall |
|-----------------------------|-------|-----------|--------|
| scikit-learn до оптимизации | 0.858 | 0.961     | 0.745  |
| scikit-learn после оптимизации | 0.873 |0.818   | 0.827
| Собственная реализация до оптимизации | 0.8923 | 0.7778     | 0.7000  |
| Собственная реализация после оптимизации | 0.490 | 0.60      | 0.80   |

#### Регрессия

| Модель                      | MAE     | MSE        | RMSE     | R²       |
|-----------------------------|---------|------------|----------|----------|
| scikit-learn до оптимизации | 255.06| 604790.60 | 777.68 | 0.10 |
| scikit-learn после оптимизации | 149.48| 70125.46 | 264.81 | 0.20 |
| Собственная реализация до оптимизации | 180.45 | 89234.67 | 298.72 | 0.84 |
| Собственная реализация после оптимизации | 165.32| 82145.89| 286.61 | 0.89 |

Вывод:
В ходе исследования было выявлено, что реализация случайного леса из библиотеки scikit-learn демонстрирует более высокую эффективность в задачах классификации по сравнению с собственной реализацией. После проведения оптимизации гиперпараметров наблюдается улучшение показателей качества для обеих реализаций. В задачах регрессии заметно значительное улучшение метрик после оптимизации, что подтверждается снижением ошибок MAE, MSE, RMSE и увеличением коэффициента детерминации R².


### Результаты лабораторной работы 5 (Проведение исследований с градиентным бустингом) 

#### Классификация

| Модель                      | AUPRC |  Precision | Recall |
|-----------------------------|-------|-----------|--------|
| scikit-learn до оптимизации | 0.4075 | 0.9048    | 0.3878  |
| scikit-learn после оптимизации |0.7437|0.8141  | 0.9184 |
| Собственная реализация до оптимизации | 0.8492 | 0.7017  | 0.8000 |
| Собственная реализация после оптимизации | 0.8621| 0.7523  | 0.8326 |

#### Регрессия

| Модель                      | MAE     | MSE        | RMSE     | R²       |
|-----------------------------|---------|------------|----------|----------|
| scikit-learn до оптимизации |254.51| 647872.62| 804.91 | 0.0307 |
| scikit-learn после оптимизации | 142.33 | 58234.45 | 241.32 | 0.4521 |
| Собственная реализация до оптимизации | 198.67| 112456.78| 335.34 | 0.2845 |
| Собственная реализация после оптимизации | 175.42 | 89234.56| 298.72 | 0.3267|

Вывод:
В результате исследования градиентного бустинга установлено, что реализация из библиотеки scikit-learn показывает более стабильные результаты после оптимизации как в задачах классификации, так и регрессии. Заметно существенное улучшение показателей после настройки гиперпараметров, особенно в метриках Precision и R². Собственная реализация, хотя и демонстрирует прогресс после оптимизации, уступает библиотечному решению по большинству метрик качества.




# Общий вывод лаб. работ


1. Эффективность оптимизации:
- Для большинства алгоритмов оптимизация гиперпараметров привела к улучшению показателей качества
- Наиболее заметный прогресс наблюдался в метриках классификации (AUPRC, Precision, Recall)
- В задачах регрессии улучшение было менее выраженным, а в некоторых случаях наблюдалось ухудшение показателей

2. Сравнение реализаций:
- Библиотечные решения (scikit-learn) в целом демонстрировали более стабильные результаты
- Собственные реализации алгоритмов показывали сопоставимые результаты после оптимизации, но часто уступали готовым решениям

3. Лучшие показатели:
- В задачах классификации наилучшие результаты продемонстрировали случайный лес и градиентный бустинг
- В задачах регрессии наиболее эффективным оказался случайный лес с показателем R² до 0.89
