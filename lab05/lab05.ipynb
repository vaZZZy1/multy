{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TksNsNjZRl2X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация"
      ],
      "metadata": {
        "id": "g8E5qncsRtDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получение данных"
      ],
      "metadata": {
        "id": "GSKtlZvPSbqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "\n",
        "csv_path = os.path.join(path, \"creditcard.csv\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "\n",
        "features = df[['Time', 'Amount']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOEgcAnaRyZ-",
        "outputId": "8db651f0-fd0e-43e4-bda9-9d0a6965201d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mlg-ulb/creditcardfraud?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 66.0M/66.0M [00:00<00:00, 98.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "\n",
        "\n",
        "# Подготовка данных\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели с оптимизированными параметрами\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42,\n",
        "    subsample=0.8,\n",
        "    n_iter_no_change=10  # ранняя остановка\n",
        ")\n",
        "\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Получение предсказаний\n",
        "y_pred = gb_model.predict(X_test_scaled)\n",
        "y_pred_proba = gb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Вычисление метрик\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_val = precision_score(y_test, y_pred)\n",
        "recall_score_val = recall_score(y_test, y_pred)\n",
        "\n",
        "# Вывод метрик\n",
        "print(f\"AUPRC : {auprc:.4f}\")\n",
        "print(f\"Precision : {precision_score_val:.4f}\")\n",
        "print(f\"Recall : {recall_score_val:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKsEAZABTFWr",
        "outputId": "c8e19847-227a-4408-8741-c095fbed4902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPRC : 0.4075\n",
            "Precision : 0.9048\n",
            "Recall : 0.3878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUPRC: 0.4075\n",
        "Значение AUPRC показывает среднюю точность модели при различных уровнях полноты. Учитывая сильный дисбаланс классов в данных, это неплохой результат, хотя есть потенциал для улучшения.\n",
        "\n",
        "Precision: 0.9048\n",
        "Очень хороший показатель точности - 90.48% предсказанных мошеннических операций действительно являются мошенническими\n",
        "\n",
        "Recall: 0.3878\n",
        "Показатель полноты говорит о том, что модель обнаруживает только 38.78% всех фактических мошеннических операций. Это относительно низкий показатель, который желательно улучшить.\n",
        "\n",
        "Модель демонстрирует высокую точность в определении мошенничества, но при этом пропускает значительную часть мошеннических операций."
      ],
      "metadata": {
        "id": "ol--3Q0WUBLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотеза: если добавим методы сэмплирования (smote), то модель значительна улучшится.\n",
        "\n",
        "Применим"
      ],
      "metadata": {
        "id": "lhrJN2HaUM_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Применение SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42,\n",
        "    subsample=0.8,\n",
        "    n_iter_no_change=5\n",
        ")\n",
        "\n",
        "gb_model.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "y_pred = gb_model.predict(X_test_scaled)\n",
        "y_pred_proba = gb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_val = precision_score(y_test, y_pred)\n",
        "recall_score_val = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"AUPRC Score: {auprc:.4f}\")\n",
        "print(f\"Precision Score: {precision_score_val:.4f}\")\n",
        "print(f\"Recall Score: {recall_score_val:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqIjaZeHUkBN",
        "outputId": "b009f26c-fdd5-48a9-dce9-60286b78d347"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPRC Score: 0.7437\n",
            "Precision Score: 0.1141\n",
            "Recall Score: 0.9184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "AUPRC (0.7437) демонстрирует приемлемую общую эффективность модели. Высокий показатель Recall (0.9184) указывает на отличное обнаружение положительных случаев. Однако низкий Precision (0.1141) свидетельствует о значительном количестве ложноположительных результатов. Модель склонна к переобнаружению мошеннических транзакций."
      ],
      "metadata": {
        "id": "p2j5LhqPnyJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "\n",
        "class MyGradientBoostingRegressor:\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.05, max_depth=3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "        self.initial_value = None\n",
        "\n",
        "    def fit(self, features, target):\n",
        "        self.initial_value = np.mean(target)\n",
        "        residual = target - self.initial_value\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
        "            tree.fit(features, residual)\n",
        "            predictions = tree.predict(features)\n",
        "            residual -= self.learning_rate * predictions\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, features):\n",
        "        predictions = np.full(features.shape[0], self.initial_value)\n",
        "        for tree in self.trees:\n",
        "            predictions += self.learning_rate * tree.predict(features)\n",
        "        return predictions\n",
        "\n",
        "    def predict_proba(self, features):\n",
        "        # Преобразование регрессионных предсказаний в вероятности\n",
        "        raw_predictions = self.predict(features)\n",
        "        probabilities = 1 / (1 + np.exp(-raw_predictions))\n",
        "        return np.vstack((1 - probabilities, probabilities)).T\n",
        "\n",
        "# Подготовка данных\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели\n",
        "gb_model = MyGradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3\n",
        ")\n",
        "\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Получение предсказаний\n",
        "y_pred_proba = gb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Вычисление метрик\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_val = precision_score(y_test, y_pred)\n",
        "recall_score_val = recall_score(y_test, y_pred)\n",
        "\n",
        "# Вывод метрик\n",
        "print(f\"AUPRC : {auprc:.4f}\")\n",
        "print(f\"Precision : {precision_score_val:.4f}\")\n",
        "print(f\"Recall : {recall_score_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "obkH_ovKm5TC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88593fd9-b294-4920-d275-fb8681c509e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPRC : 0.8492\n",
            "Precision : 0.0017\n",
            "Recall : 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попытаемся улучшить метрики с приминением гиперпараметров"
      ],
      "metadata": {
        "id": "FOVQTgdoq5og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class OptimizedGradientBoostingRegressor(BaseEstimator, RegressorMixin):\n",
        "    def init(self, n_estimators=100, learning_rate=0.05, max_depth=3, min_samples_split=2,\n",
        "                 min_samples_leaf=1, subsample=1.0, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.subsample = subsample\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "        self.feature_importances_ = None\n",
        "\n",
        "    def _subsample(self, X, y):\n",
        "        if self.subsample == 1.0:\n",
        "            return X, y\n",
        "        n_samples = int(X.shape[0] * self.subsample)\n",
        "        indices = np.random.choice(X.shape[0], n_samples, replace=False)\n",
        "        return X[indices], y[indices]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(self.random_state)\n",
        "        self.initial_prediction = np.mean(y)\n",
        "        current_predictions = np.full_like(y, self.initial_prediction, dtype=np.float64)\n",
        "\n",
        "        # Инициализация массива важности признаков\n",
        "        self.feature_importances_ = np.zeros(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            residuals = y - current_predictions\n",
        "\n",
        "            # Подвыборка данных\n",
        "            X_subset, residuals_subset = self._subsample(X, residuals)\n",
        "\n",
        "            # Создание и обучение дерева\n",
        "            tree = DecisionTreeRegressor(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf,\n",
        "                random_state=self.random_state\n",
        "            )\n",
        "\n",
        "            tree.fit(X_subset, residuals_subset)\n",
        "\n",
        "            # Обновление важности признаков\n",
        "            self.feature_importances_ += tree.feature_importances_\n",
        "\n",
        "            # Обновление предсказаний\n",
        "            current_predictions += self.learning_rate * tree.predict(X)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "        # Нормализация важности признаков\n",
        "        self.feature_importances_ /= self.n_estimators\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.full(X.shape[0], self.initial_prediction)\n",
        "        for tree in self.trees:\n",
        "            predictions += self.learning_rate * tree.predict(X)\n",
        "        return predictions\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        raw_predictions = self.predict(X)\n",
        "        probabilities = 1 / (1 + np.exp(-raw_predictions))\n",
        "        return np.vstack((1 - probabilities, probabilities)).T\n",
        "\n",
        "# Функция для поиска оптимальных гиперпараметров\n",
        "def find_best_params(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 4, 5],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2],\n",
        "        'subsample': [0.8, 1.0]\n",
        "    }\n",
        "\n",
        "    model = OptimizedGradientBoostingRegressor()\n",
        "    grid_search = GridSearchCV(\n",
        "        model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_params_\n",
        "\n",
        "# Использование модели\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Поиск лучших параметров\n",
        "best_params = find_best_params(X_train_scaled, y_train)\n",
        "\n",
        "# Обучение модели с лучшими параметрами\n",
        "optimized_model = OptimizedGradientBoostingRegressor(**best_params, random_state=42)\n",
        "optimized_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Получение предсказаний\n",
        "y_pred_proba = optimized_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Вычисление и вывод метрик\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "auprc = auc(recall, precision)\n",
        "precision_score_val = precision_score(y_test, y_pred)\n",
        "recall_score_val = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"AUPRC: {auprc:.4f}\")\n",
        "print(f\"Precision: {precision_score_val:.4f}\")\n",
        "print(f\"Recall: {recall_score_val:.4f}\")"
      ],
      "metadata": {
        "id": "S7dk2Fnxq411"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Регрессия"
      ],
      "metadata": {
        "id": "5mo0QXx_rugB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"rohitsahoo/sales-forecasting\")\n",
        "\n",
        "csv_path = os.path.join(path, \"train.csv\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "VFjw-2RVrxH4",
        "outputId": "1bf037c8-0e6e-492c-c88f-3d64b8c01a59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rohitsahoo/sales-forecasting?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480k/480k [00:00<00:00, 17.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
              "0       1  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
              "1       2  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
              "2       3  CA-2017-138688  12/06/2017  16/06/2017    Second Class    DV-13045   \n",
              "3       4  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
              "4       5  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
              "\n",
              "     Customer Name    Segment        Country             City       State  \\\n",
              "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
              "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
              "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
              "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
              "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
              "\n",
              "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
              "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
              "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
              "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
              "3      33311.0  South  FUR-TA-10000577        Furniture       Tables   \n",
              "4      33311.0  South  OFF-ST-10000760  Office Supplies      Storage   \n",
              "\n",
              "                                        Product Name     Sales  \n",
              "0                  Bush Somerset Collection Bookcase  261.9600  \n",
              "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400  \n",
              "2  Self-Adhesive Address Labels for Typewriters b...   14.6200  \n",
              "3      Bretford CR4500 Series Slim Rectangular Table  957.5775  \n",
              "4                     Eldon Fold 'N Roll Cart System   22.3680  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0109984e-19cf-481c-aa96-1ab772eb1e98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row ID</th>\n",
              "      <th>Order ID</th>\n",
              "      <th>Order Date</th>\n",
              "      <th>Ship Date</th>\n",
              "      <th>Ship Mode</th>\n",
              "      <th>Customer ID</th>\n",
              "      <th>Customer Name</th>\n",
              "      <th>Segment</th>\n",
              "      <th>Country</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Postal Code</th>\n",
              "      <th>Region</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub-Category</th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CA-2017-152156</td>\n",
              "      <td>08/11/2017</td>\n",
              "      <td>11/11/2017</td>\n",
              "      <td>Second Class</td>\n",
              "      <td>CG-12520</td>\n",
              "      <td>Claire Gute</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Henderson</td>\n",
              "      <td>Kentucky</td>\n",
              "      <td>42420.0</td>\n",
              "      <td>South</td>\n",
              "      <td>FUR-BO-10001798</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>Bookcases</td>\n",
              "      <td>Bush Somerset Collection Bookcase</td>\n",
              "      <td>261.9600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>CA-2017-152156</td>\n",
              "      <td>08/11/2017</td>\n",
              "      <td>11/11/2017</td>\n",
              "      <td>Second Class</td>\n",
              "      <td>CG-12520</td>\n",
              "      <td>Claire Gute</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Henderson</td>\n",
              "      <td>Kentucky</td>\n",
              "      <td>42420.0</td>\n",
              "      <td>South</td>\n",
              "      <td>FUR-CH-10000454</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>Chairs</td>\n",
              "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
              "      <td>731.9400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>CA-2017-138688</td>\n",
              "      <td>12/06/2017</td>\n",
              "      <td>16/06/2017</td>\n",
              "      <td>Second Class</td>\n",
              "      <td>DV-13045</td>\n",
              "      <td>Darrin Van Huff</td>\n",
              "      <td>Corporate</td>\n",
              "      <td>United States</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>California</td>\n",
              "      <td>90036.0</td>\n",
              "      <td>West</td>\n",
              "      <td>OFF-LA-10000240</td>\n",
              "      <td>Office Supplies</td>\n",
              "      <td>Labels</td>\n",
              "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
              "      <td>14.6200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>US-2016-108966</td>\n",
              "      <td>11/10/2016</td>\n",
              "      <td>18/10/2016</td>\n",
              "      <td>Standard Class</td>\n",
              "      <td>SO-20335</td>\n",
              "      <td>Sean O'Donnell</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Fort Lauderdale</td>\n",
              "      <td>Florida</td>\n",
              "      <td>33311.0</td>\n",
              "      <td>South</td>\n",
              "      <td>FUR-TA-10000577</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>Tables</td>\n",
              "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
              "      <td>957.5775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>US-2016-108966</td>\n",
              "      <td>11/10/2016</td>\n",
              "      <td>18/10/2016</td>\n",
              "      <td>Standard Class</td>\n",
              "      <td>SO-20335</td>\n",
              "      <td>Sean O'Donnell</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>United States</td>\n",
              "      <td>Fort Lauderdale</td>\n",
              "      <td>Florida</td>\n",
              "      <td>33311.0</td>\n",
              "      <td>South</td>\n",
              "      <td>OFF-ST-10000760</td>\n",
              "      <td>Office Supplies</td>\n",
              "      <td>Storage</td>\n",
              "      <td>Eldon Fold 'N Roll Cart System</td>\n",
              "      <td>22.3680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0109984e-19cf-481c-aa96-1ab772eb1e98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0109984e-19cf-481c-aa96-1ab772eb1e98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0109984e-19cf-481c-aa96-1ab772eb1e98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15908983-fdab-475b-9bf8-014b2e9761e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15908983-fdab-475b-9bf8-014b2e9761e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15908983-fdab-475b-9bf8-014b2e9761e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9800,\n  \"fields\": [\n    {\n      \"column\": \"Row ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2829,\n        \"min\": 1,\n        \"max\": 9800,\n        \"num_unique_values\": 9800,\n        \"samples\": [\n          533,\n          873,\n          1150\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Order ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4922,\n        \"samples\": [\n          \"CA-2018-105809\",\n          \"CA-2018-144491\",\n          \"CA-2018-147564\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Order Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1230,\n        \"samples\": [\n          \"21/06/2018\",\n          \"20/04/2016\",\n          \"20/05/2017\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ship Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1326,\n        \"samples\": [\n          \"26/08/2015\",\n          \"14/12/2015\",\n          \"19/04/2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ship Mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Standard Class\",\n          \"Same Day\",\n          \"Second Class\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 793,\n        \"samples\": [\n          \"DJ-13510\",\n          \"MD-17350\",\n          \"NF-18475\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 793,\n        \"samples\": [\n          \"Don Jones\",\n          \"Maribeth Dona\",\n          \"Neil Franz\\u00f6sisch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Segment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Consumer\",\n          \"Corporate\",\n          \"Home Office\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"United States\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 529,\n        \"samples\": [\n          \"Burlington\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"Delaware\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Postal Code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32041.22341281317,\n        \"min\": 1040.0,\n        \"max\": 99301.0,\n        \"num_unique_values\": 626,\n        \"samples\": [\n          56301.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"West\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1861,\n        \"samples\": [\n          \"TEC-PH-10001580\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Furniture\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub-Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Bookcases\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1849,\n        \"samples\": [\n          \"Imation\\u00a032GB Pocket Pro USB 3.0\\u00a0Flash Drive\\u00a0- 32 GB - Black - 1 P ...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 626.6518748388047,\n        \"min\": 0.444,\n        \"max\": 22638.48,\n        \"num_unique_values\": 5757,\n        \"samples\": [\n          35.34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Создаем копию датафрейма\n",
        "df = df.copy()\n",
        "\n",
        "# Заполняем пропуски в Postal Code\n",
        "df.loc[:, 'Postal Code'] = df['Postal Code'].fillna(df['Postal Code'].median())\n",
        "\n",
        "# Преобразуем даты с указанием формата и обработкой ошибок\n",
        "try:\n",
        "    df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
        "except:\n",
        "    df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
        "\n",
        "try:\n",
        "    df['Ship Date'] = pd.to_datetime(df['Ship Date'], format='%d/%m/%Y')\n",
        "except:\n",
        "    df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
        "\n",
        "# Создаем новые признаки\n",
        "df['Ship Days'] = (df['Ship Date'] - df['Order Date']).dt.total_seconds() / (24 * 60 * 60)\n",
        "df['Order Year'] = df['Order Date'].dt.year\n",
        "df['Order Month'] = df['Order Date'].dt.month\n",
        "\n",
        "# Кодируем категориальные признаки\n",
        "categorical_columns = ['Ship Mode', 'Segment', 'Country', 'Region', 'Category', 'Sub-Category']\n",
        "le = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    df.loc[:, col + '_Encoded'] = le.fit_transform(df[col])\n",
        "\n",
        "# Выбираем признаки для модели\n",
        "features = ['Postal Code', 'Order Year', 'Order Month', 'Ship Days'] + \\\n",
        "          [col + '_Encoded' for col in categorical_columns]\n",
        "\n",
        "# Подготовка данных для модели\n",
        "X = df[features]\n",
        "y = df['Sales']\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Делаем предсказания\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Вычисляем метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Выводим метрики\n",
        "print(f'MAE: {mae:.2f}')\n",
        "print(f'MSE: {mse:.2f}')\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'R²: {r2:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr3iFmDnsV9l",
        "outputId": "501887b6-204a-455b-ee3c-3ca2dca1731d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 254.51\n",
            "MSE: 647872.62\n",
            "RMSE: 804.91\n",
            "R²: 0.0307\n",
            "\n",
            "Проверка преобразования дат:\n",
            "  Order Date  Ship Date  Ship Days\n",
            "0 2017-11-08 2017-11-11        3.0\n",
            "1 2017-11-08 2017-11-11        3.0\n",
            "2 2017-06-12 2017-06-16        4.0\n",
            "3 2016-10-11 2016-10-18        7.0\n",
            "4 2016-10-11 2016-10-18        7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные метрик неплохие, но попробуем подобрать оптимальные гиперпараметры"
      ],
      "metadata": {
        "id": "LGS3yW9OtF0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Заполняем пропуски в Postal Code\n",
        "df['Postal Code'].fillna(df['Postal Code'].median(), inplace=True)\n",
        "\n",
        "# Преобразуем даты\n",
        "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
        "df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
        "df['Ship Days'] = (df['Ship Date'] - df['Order Date']).dt.days\n",
        "df['Order Year'] = df['Order Date'].dt.year\n",
        "df['Order Month'] = df['Order Date'].dt.month\n",
        "\n",
        "# Кодируем категориальные признаки\n",
        "categorical_columns = ['Ship Mode', 'Segment', 'Country', 'Region', 'Category', 'Sub-Category']\n",
        "le = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    df[col + '_Encoded'] = le.fit_transform(df[col])\n",
        "\n",
        "# Выбираем признаки для модели\n",
        "features = ['Postal Code', 'Order Year', 'Order Month', 'Ship Days'] + \\\n",
        "          [col + '_Encoded' for col in categorical_columns]\n",
        "\n",
        "# Подготовка данных для модели\n",
        "X = df[features]\n",
        "y = df['Sales']\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Определяем параметры для оптимизации\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Создаем базовую модель\n",
        "base_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Выполняем поиск по сетке с перекрестной проверкой\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Обучаем модель с поиском оптимальных параметров\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Выводим лучшие параметры\n",
        "print(\"\\nЛучшие параметры:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Получаем лучшую модель\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Делаем предсказания с использованием лучшей модели\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Вычисляем метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Выводим метрики\n",
        "print(\"\\nМетрики качества модели:\")\n",
        "print(f'MAE: {mae:.2f}')\n",
        "print(f'MSE: {mse:.2f}')\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'R²: {r2:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR77KJ9ytJTu",
        "outputId": "faf8df98-72a7-44fb-949a-ca408332e0f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-3932a1e79098>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Postal Code'].fillna(df['Postal Code'].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Лучшие параметры:\n",
            "{'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50, 'subsample': 1.0}\n",
            "\n",
            "Метрики качества модели:\n",
            "MAE: 242.86\n",
            "MSE: 561605.74\n",
            "RMSE: 749.40\n",
            "R²: 0.1598\n"
          ]
        }
      ]
    }
  ]
}